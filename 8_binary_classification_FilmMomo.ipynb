{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "063d7480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã tạo xong 1000 câu hỏi không trùng và lưu vào non_review_questions.csv\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# Mở rộng tiền tố\n",
    "prefixes = [\n",
    "    \"Bạn có thể giúp tôi\", \"Làm sao để\", \"Tôi nên làm gì khi\", \"Bạn biết\", \"Có cách nào\",\n",
    "    \"Tại sao lại\", \"Lúc nào thì\", \"Chúng ta có thể\", \"Tôi đang cần\", \"Làm thế nào để\",\n",
    "    \"Nếu tôi muốn\", \"Gợi ý giúp tôi\", \"Tôi đang gặp khó khăn trong việc\", \"Có nên\", \"Vì sao tôi nên\",\"Shop giới thiệu\"\n",
    "    \"Tôi đang băn khoăn về việc\", \"Mình cần lời khuyên về\", \"Tôi cần được hướng dẫn\", \"Giải thích giúp tôi\", \"Có cái gì hay thì giới thiệu\", \"Bạn là ai biết\", \"Tôi là ai biết\",\n",
    "    \"Theo bạn thì\"\n",
    "]\n",
    "\n",
    "# Mở rộng chủ đề\n",
    "topics = [\n",
    "    \"học tiếng Anh hiệu quả?\", \"trồng rau sạch tại nhà?\", \"đi đến Hà Nội nhanh nhất?\", \"nấu phở bò ngon?\",\n",
    "    \"đọc sách nhanh hơn?\", \"mua vé máy bay giá rẻ?\", \"liên hệ với tổng đài?\", \"tìm việc làm online?\",\n",
    "    \"giảm căng thẳng sau giờ làm?\", \"học tốt môn Toán?\", \"du lịch Đà Lạt tự túc?\", \"tăng chiều cao tuổi dậy thì?\",\n",
    "    \"chăm sóc da mặt đúng cách?\", \"học lập trình Python?\", \"giảm cân an toàn?\", \"nuôi chó tại nhà?\",\n",
    "    \"sắp xếp thời gian hiệu quả?\", \"chọn ngành đại học phù hợp?\", \"tiết kiệm tiền lương?\", \"nấu cơm bằng nồi điện?\",\n",
    "    \"tìm nhà trọ sinh viên?\", \"sống xanh và thân thiện với môi trường?\", \"xem phim hay trên Netflix?\",\n",
    "    \"học online không buồn ngủ?\", \"bảo vệ mắt khi dùng máy tính?\", \"tăng năng suất làm việc?\", \n",
    "    \"tự học tiếng Trung?\", \"du lịch nước ngoài lần đầu?\", \"mua laptop cho sinh viên?\", \"tập gym cho người mới bắt đầu?\", \"phim gì hay giới thiệu đi\"\n",
    "]\n",
    "\n",
    "# Sinh câu hỏi không trùng\n",
    "questions = set()\n",
    "while len(questions) < 1000:\n",
    "    question = f\"{random.choice(prefixes)} {random.choice(topics)}\"\n",
    "    # Gắn số ngẫu nhiên để tránh trùng (sẽ loại sau)\n",
    "    question += f\" #{random.randint(1, 1000000)}\"\n",
    "    questions.add(question)\n",
    "\n",
    "# Loại bỏ phần #random\n",
    "cleaned_questions = [q.rsplit(\"#\", 1)[0].strip() for q in questions]\n",
    "\n",
    "# Ghi vào DataFrame\n",
    "df = pd.DataFrame(cleaned_questions, columns=[\"text\"])\n",
    "df[\"label\"] = 0  # Nhãn 0: không phải review phim\n",
    "\n",
    "# Lưu file CSV\n",
    "df.to_csv(\"non_review_questions.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"Đã tạo xong 1000 câu hỏi không trùng và lưu vào non_review_questions.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "378299ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đọc file chứa 1000 câu hỏi thông thường (label 0)\n",
    "non_review_df = pd.read_csv(\"non_review_questions.csv\")\n",
    "\n",
    "# Đọc file momo review gốc (label 1)\n",
    "momo_df = pd.read_csv(\"momo_reviews_balanced.csv\")\n",
    "\n",
    "# Chọn 1000 câu đánh giá phim từ momo (giả sử cột review là 'Noi_dung_sach_giu_dau')\n",
    "momo_review_df = momo_df[['Noi_dung_sach_giu_dau']].dropna().sample(n=1000, random_state=42)\n",
    "momo_review_df = momo_review_df.rename(columns={'Noi_dung_sach_giu_dau': 'text'})\n",
    "momo_review_df['label'] = 1  # Gán nhãn 1 cho câu review phim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bfc18d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    1000\n",
      "1    1000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Kết hợp hai tập lại với nhau\n",
    "combined_df = pd.concat([momo_review_df, non_review_df], ignore_index=True)\n",
    "\n",
    "# Xáo trộn thứ tự để huấn luyện tốt hơn\n",
    "combined_df = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Kiểm tra số lượng\n",
    "print(combined_df['label'].value_counts())  # Nên ra 1000 (label=0) và 1000 (label=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "851c7c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu file review_detection_dataset.csv gồm cả câu hỏi và review phim.\n"
     ]
    }
   ],
   "source": [
    "combined_df.to_csv(\"review_detection_dataset.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"Đã lưu file review_detection_dataset.csv gồm cả câu hỏi và review phim.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1810d26c",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3176d066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas scikit-learn joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87e7e28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.50%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "\n",
    "# Bước 1: Đọc dữ liệu từ file CSV\n",
    "df = pd.read_csv(\"review_detection_dataset.csv\")\n",
    "\n",
    "# Bước 2: Tách dữ liệu và nhãn\n",
    "X = df[\"text\"]\n",
    "y = df[\"label\"]\n",
    "\n",
    "# Bước 3: Chia tập train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Bước 4: Vector hóa bằng TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Bước 5: Huấn luyện mô hình\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Bước 6: Lưu mô hình và vectorizer\n",
    "joblib.dump(vectorizer, \"review_vectorizer.pkl\")\n",
    "joblib.dump(model, \"review_detector_model.pkl\")\n",
    "\n",
    "# Bước 7: Kiểm tra độ chính xác\n",
    "accuracy = model.score(X_test_tfidf, y_test)\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
